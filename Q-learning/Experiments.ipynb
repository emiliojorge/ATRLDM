{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "from lake_envs import *\n",
    "import value_iteration\n",
    "import utility\n",
    "import tabQ_learning\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "\n",
    "6*10^5 seems to be a sufficient amount of itterations to be 0.05-optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function took 15952.613 ms\n",
      "Great!! The value of your provided Q is 0.7703915957613292, and this is 0.05 close to the optimal value of 0.7737809374999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Deterministic-4x4-FrozenLake-v0')\n",
    "Q = tabQ_learning.Qlearning(env, num_observations = 6*10**5)\n",
    "value_iteration.isQvalueErrorEpsilonClose(env, Q, gamma=0.95, epsilon=0.05)\n",
    "#utility.compute_statistics(env, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5\n",
    "A less than linear decay seems to be beneficial. This also seems reasonable from the \\sum alpha = inf but also \\sum alpha^2 < inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function took 125.240 ms\n",
      "[[ 0.73509189  0.77378094  0.77378094  0.73509189]\n",
      " [ 0.73509189  0.          0.81450625  0.77378094]\n",
      " [ 0.77378094  0.857375    0.77378094  0.81450625]\n",
      " [ 0.81450625  0.          0.77378094  0.77378094]\n",
      " [ 0.77378094  0.81450625  0.          0.73509189]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.9025      0.          0.81450625]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.81450625  0.          0.857375    0.77378094]\n",
      " [ 0.81450625  0.9025      0.9025      0.        ]\n",
      " [ 0.857375    0.95        0.          0.857375  ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.9025      0.95        0.857375  ]\n",
      " [ 0.9025      0.95        1.          0.9025    ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "Great!! The value of your provided Q is 0.7737809374999999, and this is 0.05 close to the optimal value of 0.7737809374999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Deterministic-4x4-FrozenLake-v0')\n",
    "lr = lambda x: utility.polynomial_learning_rate(x, 0.000)\n",
    "Q = tabQ_learning.Qlearning(env,gamma=0.95, num_observations = 4*10**3, learning_rate=lr )\n",
    "print(Q)\n",
    "value_iteration.isQvalueErrorEpsilonClose(env, Q, gamma=0.95, epsilon=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function took 4154.796 ms\n",
      "Great!! The value of your provided Q is 0.754141827411168, and this is 0.05 close to the optimal value of 0.7737809374999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('Deterministic-4x4-FrozenLake-v0')\n",
    "Q = tabQ_learning.speedy_Qlearning(env,gamma=0.95, num_observations = 6*10**4 )\n",
    "value_iteration.isQvalueErrorEpsilonClose(env, Q, gamma=0.95, epsilon=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Q8 \n",
    "It seems that with the default learning rate speedy Q-learning beats the standard version with at least an order of magnitude but still takes long in terms of execution time. This would not be a factor if the simulation environment took more time relative to the algorithm execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
