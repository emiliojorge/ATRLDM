{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn import svm\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, env, num_experiments=10, num_episodes=100, num_timesteps=1000):\n",
    "        self.env = env\n",
    "        self.num_experiments=num_experiments\n",
    "        self.num_episodes=num_episodes\n",
    "        self.num_timesteps=num_timesteps\n",
    "    def getAction(self, state):\n",
    "        return self.env.action_space.sample()\n",
    "    def getQValue(self, state):\n",
    "        pass\n",
    "    def update(self, state, action, reward, nextState):\n",
    "        pass\n",
    "    def run(self):\n",
    "        episodic_return = np.zeros((self.num_experiments, self.num_episodes))\n",
    "        for i in range(self.num_experiments):\n",
    "            for j in range(self.num_episodes):\n",
    "                acc_reward = 0\n",
    "                for t in range(self.num_timesteps):\n",
    "                    observation = self.env.reset()\n",
    "                    action = self.getAction(observation)\n",
    "                    nextObservation, reward, done, info = self.env.step(action)\n",
    "                    if done:\n",
    "                        break\n",
    "                    acc_reward += reward\n",
    "                episodic_return[i, j] += acc_reward\n",
    "        return episodic_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-bae16a39878e>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-bae16a39878e>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    def getAction(self, state, epsilon):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PGAgent:\n",
    "    def __init__(self, env, num_experiments=10, num_episodes=100, num_timesteps=1000, replay_buffer_size=10000, epsilon=0.05):\n",
    "        self.env = env\n",
    "        self.num_experiments=num_experiments\n",
    "        self.num_episodes=num_episodes\n",
    "        self.num_timesteps=num_timesteps\n",
    "        self.num_actions = 2\n",
    "        self.replay_buffer_size = replay_buffer_size\n",
    "        self.observation_size = self.env.observation_space.shape[0]\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        #####Network\n",
    "        state = tf.placeholder(tf.float32, [None, self.observation_size])\n",
    "        w1 = tf.layers.dense(state, 16)\n",
    "        w2 = tf.layers.dense(w1, 32)\n",
    "        self.Q_network = tf.layers.dense(w2, self.num_actions)\n",
    "    \n",
    "        self.Q_target = tf.Variable(self.Q_network.initialized_value())\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.initialize_all_variables())\n",
    "        \n",
    "        \n",
    "\n",
    "        # self.alpha = 0.2\n",
    "        # self.beta = 0.2\n",
    "    \n",
    "        # Your code here!\n",
    "        # Features can for example come from a grid of Radial Basis Functions\n",
    "        # or some other model that lets you do predictions over unvisited states\n",
    "        # self.features = ?\n",
    "        \n",
    "        ### You can store parts of the state space like this and build your kernels\n",
    "        #\n",
    "        # self.observations = [[] for i in range(num_action)]\n",
    "        # for i in self.observations:\n",
    "        #     i.append(self.env.observation_space.sample())\n",
    "        #\n",
    "        ###\n",
    "        \n",
    "        ### You need to store your weights somewhere\n",
    "        ### if you are using actor-critic you probably want weights for both the policy and the value function!\n",
    "        #\n",
    "        # self.PIweights = np.ones((num_action,?))\n",
    "        # self.Vweights = np.ones((num_action,?))\n",
    "        #\n",
    "        ###\n",
    "        \n",
    "    ### This method will return a sampled action\n",
    "    ### from your policy\n",
    "    def getAction(self, state, epsilon=self.epsilon):\n",
    "        Q = self.getQvalues(state)\n",
    "        if random.random()< epsilon:\n",
    "            return random.choice(range(self.num_actions))\n",
    "        else:\n",
    "            return np.argmax(Q)\n",
    "        \n",
    "    def getQValues(self, state):\n",
    "        return self.session.run(self.Q_network, feeddict= {self.state: state})\n",
    "    \n",
    "                \n",
    "    \n",
    "    def update(self, state, action, reward, nextState):\n",
    "        loss = 1/2*(reward + self.Q_network\n",
    "        i = 0\n",
    "        feats = self.getFeature(state, action)\n",
    "        for f in feats:\n",
    "            #self.PIweights[action,:] = self.PIweights[action,:].flatten() + (self.alpha * (f - ExPI * f) * delta)         \n",
    "            #self.Vweights[action,:] = self.Vweights[action,:].flatten() + self.beta * delta * feat\n",
    "            #self.observations[action].append(f)\n",
    "            i += 1\n",
    "       \n",
    "    def run(self):\n",
    "        episodic_return = np.zeros((self.num_experiments, self.num_episodes))\n",
    "        for i in range(self.num_experiments):\n",
    "            # first collect some MC returns \n",
    "            for j in range(self.num_episodes):\n",
    "                acc_reward = 0\n",
    "                observation = self.env.reset()\n",
    "                for t in range(self.num_timesteps):\n",
    "                    action = self.getAction(observation)\n",
    "                    nextObservation, reward, done, info = self.env.step(action)\n",
    "                    self.update(observation, action, reward, nextObservation)\n",
    "                    acc_reward += reward\n",
    "                    if done:\n",
    "                        break\n",
    " \n",
    "                    observation = nextObservation\n",
    "                episodic_return[i, j] += acc_reward\n",
    "                print acc_reward\n",
    "        return episodic_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-6-22f72f063969>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-22f72f063969>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print eps_return.shape\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "# pg agent\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "ragent = PGAgent(env, num_episodes=1000, num_experiments=2)\n",
    "eps_return = ragent.run()\n",
    "print eps_return.shape\n",
    "print np.mean(eps_return, axis=0)\n",
    "plt.scatter()\n",
    "\n",
    "# random agent\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "ragent = RandomAgent(env)\n",
    "eps_return = ragent.run()\n",
    "print np.mean(eps_return, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CLICOLOR': '1',\n",
       " 'CLUTTER_IM_MODULE': 'xim',\n",
       " 'COMPIZ_CONFIG_PROFILE': 'ubuntu',\n",
       " 'CUDA_HOME': '/usr/local/cuda-8.0',\n",
       " 'DBUS_DEBUG_OUTPUT': '1',\n",
       " 'DBUS_SESSION_BUS_ADDRESS': 'unix:abstract=/tmp/dbus-J2ocEPX1sD,guid=d7597fdd837d14be602d178e5ab27df2',\n",
       " 'DBUS_STARTER_ADDRESS': 'unix:abstract=/tmp/dbus-J2ocEPX1sD,guid=d7597fdd837d14be602d178e5ab27df2',\n",
       " 'DBUS_STARTER_BUS_TYPE': 'session',\n",
       " 'DEFAULTS_PATH': '/usr/share/gconf/ubuntu.default.path',\n",
       " 'DESKTOP_SESSION': 'ubuntu',\n",
       " 'DISPLAY': ':0',\n",
       " 'DYLD_LIBRARY_PATH': '/home/emilio/torch/install/lib:/home/emilio/torch/install/lib:/home/emilio/torch/install/lib:',\n",
       " 'GDMSESSION': 'ubuntu',\n",
       " 'GDM_LANG': 'en_US',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'GNOME_DESKTOP_SESSION_ID': 'this-is-deprecated',\n",
       " 'GNOME_KEYRING_CONTROL': '',\n",
       " 'GNOME_KEYRING_PID': '',\n",
       " 'GPG_AGENT_INFO': '/home/emilio/.gnupg/S.gpg-agent:0:1',\n",
       " 'GTK2_MODULES': 'overlay-scrollbar',\n",
       " 'GTK_IM_MODULE': 'ibus',\n",
       " 'GTK_MODULES': 'gail:atk-bridge:unity-gtk-module',\n",
       " 'HOME': '/home/emilio',\n",
       " 'IM_CONFIG_PHASE': '1',\n",
       " 'INSTANCE': '',\n",
       " 'JOB': 'xsession-init',\n",
       " 'JPY_PARENT_PID': '6778',\n",
       " 'LANG': 'en_US.UTF-8',\n",
       " 'LANGUAGE': 'en_US',\n",
       " 'LC_ADDRESS': 'sv_SE.UTF-8',\n",
       " 'LC_IDENTIFICATION': 'sv_SE.UTF-8',\n",
       " 'LC_MEASUREMENT': 'sv_SE.UTF-8',\n",
       " 'LC_MONETARY': 'sv_SE.UTF-8',\n",
       " 'LC_NAME': 'sv_SE.UTF-8',\n",
       " 'LC_NUMERIC': 'sv_SE.UTF-8',\n",
       " 'LC_PAPER': 'sv_SE.UTF-8',\n",
       " 'LC_TELEPHONE': 'sv_SE.UTF-8',\n",
       " 'LC_TIME': 'sv_SE.UTF-8',\n",
       " 'LD_LIBRARY_PATH': '/home/emilio/torch/install/lib:/usr/local/cuda-8.0/lib64:/home/emilio/torch/install/lib:/home/emilio/torch/install/lib:',\n",
       " 'LESSCLOSE': '/usr/bin/lesspipe %s %s',\n",
       " 'LESSOPEN': '| /usr/bin/lesspipe %s',\n",
       " 'LOGNAME': 'emilio',\n",
       " 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:',\n",
       " 'LUA_CPATH': '/home/emilio/torch/install/lib/?.so;/home/emilio/.luarocks/lib/lua/5.1/?.so;/home/emilio/torch/install/lib/lua/5.1/?.so;/home/emilio/torch/install/lib/?.so;./?.so;/usr/local/lib/lua/5.1/?.so;/usr/local/lib/lua/5.1/loadall.so',\n",
       " 'LUA_PATH': '/home/emilio/.luarocks/share/lua/5.1/?.lua;/home/emilio/.luarocks/share/lua/5.1/?/init.lua;/home/emilio/torch/install/share/lua/5.1/?.lua;/home/emilio/torch/install/share/lua/5.1/?/init.lua;./?.lua;/home/emilio/torch/install/share/luajit-2.1.0-beta1/?.lua;/usr/local/share/lua/5.1/?.lua;/usr/local/share/lua/5.1/?/init.lua',\n",
       " 'MANDATORY_PATH': '/usr/share/gconf/ubuntu.mandatory.path',\n",
       " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       " 'PAGER': 'cat',\n",
       " 'PATH': '/home/emilio/anaconda3/bin:/home/emilio/torch/install/bin:/home/emilio/anaconda3/bin:/usr/local/cuda-8.0/bin:/home/emilio/torch/install/bin:/home/emilio/torch/install/bin:/home/emilio/bin:/home/emilio/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin',\n",
       " 'PWD': '/home/emilio/ATRLDM/Function approximation',\n",
       " 'QT4_IM_MODULE': 'xim',\n",
       " 'QT_ACCESSIBILITY': '1',\n",
       " 'QT_IM_MODULE': 'ibus',\n",
       " 'QT_LINUX_ACCESSIBILITY_ALWAYS_ON': '1',\n",
       " 'QT_QPA_PLATFORMTHEME': 'appmenu-qt5',\n",
       " 'SESSIONTYPE': 'gnome-session',\n",
       " 'SESSION_MANAGER': 'local/emilio-desktop:@/tmp/.ICE-unix/4957,unix/emilio-desktop:/tmp/.ICE-unix/4957',\n",
       " 'SHELL': '/bin/bash',\n",
       " 'SHLVL': '1',\n",
       " 'SSH_AUTH_SOCK': '/run/user/1000/keyring/ssh',\n",
       " 'TERM': 'xterm-color',\n",
       " 'UPSTART_EVENTS': 'starting',\n",
       " 'UPSTART_INSTANCE': '',\n",
       " 'UPSTART_JOB': 'dbus',\n",
       " 'UPSTART_SESSION': 'unix:abstract=/com/ubuntu/upstart-session/1000/4734',\n",
       " 'USER': 'emilio',\n",
       " 'VTE_VERSION': '4205',\n",
       " 'WINDOWID': '73400330',\n",
       " 'XAUTHORITY': '/home/emilio/.Xauthority',\n",
       " 'XDG_CONFIG_DIRS': '/etc/xdg/xdg-ubuntu:/usr/share/upstart/xdg:/etc/xdg',\n",
       " 'XDG_CURRENT_DESKTOP': 'Unity',\n",
       " 'XDG_DATA_DIRS': '/usr/share/ubuntu:/usr/share/gnome:/usr/local/share:/usr/share:/var/lib/snapd/desktop:/var/lib/snapd/desktop',\n",
       " 'XDG_GREETER_DATA_DIR': '/var/lib/lightdm-data/emilio',\n",
       " 'XDG_MENU_PREFIX': 'gnome-',\n",
       " 'XDG_RUNTIME_DIR': '/run/user/1000',\n",
       " 'XDG_SEAT': 'seat0',\n",
       " 'XDG_SEAT_PATH': '/org/freedesktop/DisplayManager/Seat0',\n",
       " 'XDG_SESSION_DESKTOP': 'ubuntu',\n",
       " 'XDG_SESSION_ID': 'c2',\n",
       " 'XDG_SESSION_PATH': '/org/freedesktop/DisplayManager/Session0',\n",
       " 'XDG_SESSION_TYPE': 'x11',\n",
       " 'XDG_VTNR': '7',\n",
       " 'XMODIFIERS': '@im',\n",
       " '_': '/home/emilio/anaconda3/bin/jupyter'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
